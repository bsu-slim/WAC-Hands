{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook gets the hand data csv file and rewrites the tendon values to align with the theory of mirror neurons. Using ridge regression, a mapping is created between visual features and tendon values. These new tendon values created from the visual features are written in a new file called hand_data_mirror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import *\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from collections import defaultdict as dd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from slir import SparseLinearRegression\n",
    "\n",
    "import operator\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "#from textblob import TextBlob\n",
    "#from textblob import Word\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "from IPython.display import Image\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib  \n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data, remove punctuation, stem, and tokenize the descriptions, and add  camera one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_raw_data():\n",
    "    data = pd.read_csv('../data/hand_data3_separated.csv',  index_col=False)\n",
    "\n",
    "    # remove punctuation\n",
    "    data['desc_list'] = data.description.apply(lambda x: [i for i in re.sub(r'[^\\w\\s]','',str(x)).lower().split()])\n",
    "    data['desc_str'] = data.desc_list.apply(lambda x: ' '.join(x))\n",
    "\n",
    "    #add one-hot encoding\n",
    "    camera_data = pd.get_dummies(data.camera_angle)\n",
    "    data = pd.concat([data, camera_data], axis=1)\n",
    "    cols = data.columns.tolist()\n",
    "    cols = cols[:8] + cols[-4:] + cols[8:-4]\n",
    "    data = data[cols]\n",
    "    \n",
    "    #get words and vocabs\n",
    "    words = [y for x in data.desc_list for y in x]\n",
    "    vocab = list(set(words))\n",
    "    print('number of unique words in our data:', len(vocab), '\\nnumber of word tokens in our data: ', len(words))\n",
    "    \n",
    "    return data, words, vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data, stack it, and clean it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_data():\n",
    "    train_data = pd.read_pickle(\"../data/train_data3_separated.pkl\")\n",
    "    test_data = pd.read_pickle(\"../data/test_data3_separated.pkl\")\n",
    "    return train_data, test_data\n",
    "\n",
    "def stack_training_data(mydata):\n",
    "    s = mydata.apply(lambda x: pd.Series(x['desc_list']),axis=1).stack().reset_index(level=1, drop=True)\n",
    "    s.name = 'word'\n",
    "    mydata = mydata.join(s)\n",
    "    return mydata\n",
    "\n",
    "def remove_unwated_words(mydata, vocab, words):\n",
    "    wanted_words = list(set(words))\n",
    "    unwanted_words = {'hand', 'and', 'the', 'a', 'with', 'is', 'are', 'to', 'of', 'finger', 'fingers', 'thumb'}\n",
    "    unwanted_tags = {}\n",
    "    for curr_word in vocab:\n",
    "        if curr_word in unwanted_words:\n",
    "            wanted_words.remove(curr_word)\n",
    "    mydata = mydata.loc[mydata['word'].isin(wanted_words)]\n",
    "    return mydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, words, vocab = read_raw_data()\n",
    "train_data, test_data = read_in_data()\n",
    "train_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Ridge Regression Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, words, vocab = read_raw_data()\n",
    "\n",
    "data.columns[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_COL = 'T1' \n",
    "END_COL = 'T5'\n",
    "V_START_COL = 'above'\n",
    "V_END_COL = 'f1000'\n",
    "\n",
    "y = train_data.ix[:,START_COL:END_COL].as_matrix()\n",
    "X = train_data.ix[:,V_START_COL:V_END_COL].as_matrix()\n",
    "y_test = test_data.ix[:,START_COL:END_COL].as_matrix()\n",
    "X_test = test_data.ix[:,V_START_COL:V_END_COL].as_matrix()\n",
    "y_all = data.ix[:,START_COL:END_COL].as_matrix()\n",
    "X_all = data.ix[:,V_START_COL:V_END_COL].as_matrix()\n",
    "\n",
    "print(\"train\", X.shape, y.shape)\n",
    "print(\"test\", X_test.shape, y_test.shape)\n",
    "print(\"all\", X_all.shape, y_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=0.0001, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=True, random_state=False, solver='auto', tol=0.01)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import *\n",
    "import numpy as np\n",
    "\n",
    "model = Ridge(alpha=0.0001, copy_X=True, fit_intercept=True, max_iter=None, normalize=True, \n",
    "              random_state=False, solver='auto', tol=0.01)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of Ridge Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import math\n",
    "\n",
    "y_actual = y_test\n",
    "y_predicted = model.predict(X_test) \n",
    "\n",
    "rms = sqrt(mean_squared_error(y_actual, y_predicted))\n",
    "print(rms)\n",
    "print(y_actual[:10])\n",
    "print(np.around(y_predicted[:10], decimals=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Produce mirror .pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tendons = model.predict(X_all) \n",
    "new_tendons.shape # this should match above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_tendons now needs to replace the columns from START_COL to END_COL\n",
    "data_old = pd.read_csv('../data/hand_data3_separated.csv',  index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modify the data\n",
    "data_new = data_old\n",
    "columns = [\"T1\", \"T2\", \"T3\", \"T4\", \"T5\"]\n",
    "for i, col in enumerate(columns):    \n",
    "    print(i, col)\n",
    "    data_new = data_new.drop([col], axis=1)\n",
    "    data_new.insert(loc=i+3, column=col, value=new_tendons[:,i],)\n",
    "    \n",
    "data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write new tedoncs to csv file\n",
    "data_new.to_csv(path_or_buf='../data/hand_data3_mirror.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
